{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from warpctc_pytorch import CTCLoss # https://github.com/SeanNaren/warp-ctc\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctcdecode\n",
    "# https://github.com/parlance/ctcdecode\n",
    "# in tf: https://github.com/githubharald/CTCWordBeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss = CTCLoss()\n",
    "# expected shape of seqLength x batchSize x alphabet_size\n",
    "probs = torch.FloatTensor([[[0.1, 0.6, 0.1, 0.1, 0.1], [0.1, 0.1, 0.6, 0.1, 0.1]]]).transpose(0, 1).contiguous()\n",
    "labels = torch.IntTensor([1, 2])\n",
    "label_sizes = torch.IntTensor([2])\n",
    "probs_sizes = torch.IntTensor([2])\n",
    "probs.requires_grad_(True)  # tells autograd to compute gradients for probs\n",
    "cost = ctc_loss(probs, labels, probs_sizes, label_sizes)\n",
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSJ():\n",
    "    \"\"\" Load the WSJ speech dataset\n",
    "        \n",
    "        Ensure WSJ_PATH is path to directory containing \n",
    "        all data files (.npy) provided on Kaggle.\n",
    "        \n",
    "        Example usage:\n",
    "            loader = WSJ()\n",
    "            trainX, trainY = loader.train\n",
    "            assert(trainX.shape[0] == 24590)\n",
    "            \n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self, path):\n",
    "        self.dev_set = None\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "        self.path  = path\n",
    "        \n",
    "    @property\n",
    "    def dev(self):\n",
    "        if self.dev_set is None:\n",
    "            self.dev_set = load_raw(self.path, 'wsj0_dev')\n",
    "        return self.dev_set\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        if self.train_set is None:\n",
    "            self.train_set = load_raw(self.path, 'wsj0_train')\n",
    "        return self.train_set\n",
    "  \n",
    "    @property\n",
    "    def test(self):\n",
    "        if self.test_set is None:\n",
    "            self.test_set = (np.load(os.path.join(self.path, 'wsj0_test.npy'), encoding='bytes'), None)\n",
    "        return self.test_set\n",
    "    \n",
    "def load_raw(path, name):\n",
    "    return (\n",
    "        np.load(os.path.join(path, '{}.npy'.format(name)), encoding='bytes'), \n",
    "        np.load(os.path.join(path, '{}_merged_labels.npy'.format(name)), encoding='bytes')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/borowis/s3\"\n",
    "wsj = WSJ(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(path)\n",
    "import phoneme_list as phl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = wsj.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1106,)\n",
      "(1106,)\n",
      "[[-4.9549413  -5.909959   -4.7054377  ...  0.26314926 -0.00832033\n",
      "   0.2449565 ]\n",
      " [-4.4155927  -7.4320974  -4.8468237  ...  0.09183788 -0.21720076\n",
      "   0.5789623 ]\n",
      " [-4.64845    -5.345671   -3.6078033  ...  0.00744247  0.19980097\n",
      "  -0.01899004]\n",
      " ...\n",
      " [-6.1085844  -6.8452053  -5.9429183  ... -1.9091392  -1.709682\n",
      "  -1.4018598 ]\n",
      " [-5.8867598  -6.644912   -4.627789   ... -2.1586275  -1.6964803\n",
      "  -1.3536029 ]\n",
      " [-4.7362947  -5.2249713  -3.899804   ... -2.992228   -2.853492\n",
      "  -2.5541077 ]]\n",
      "[36 15  8 19 23 27 18 26 32 33  8 14 40 34 22 44  8 26 22 37 17  8 41 37\n",
      " 40 37 22 19  9 33 43  8 29 22 28 28 30 41 16 27 12 17  7 28 14 14 22 34\n",
      " 16 27 12 17  0 36]\n"
     ]
    }
   ],
   "source": [
    "print(dev[0].shape)\n",
    "print(dev[1].shape)\n",
    "print(dev[0][0])\n",
    "print(dev[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = phl.PHONEME_LIST\n",
    "phonemes_map = phl.PHONEME_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIL', 'DH', 'AH', 'F', 'IY', 'M', 'EY', 'L', 'P', 'R', 'AH', 'D', 'UW', 'S', 'IH', 'Z', 'AH', 'L', 'IH', 'T', 'ER', 'AH', 'V', 'T', 'UW', 'T', 'IH', 'F', 'AO', 'R', 'Y', 'AH', 'NG', 'IH', 'N', 'N', 'OW', 'V', 'EH', 'M', 'B', 'ER', 'AE', 'N', 'D', 'D', 'IH', 'S', 'EH', 'M', 'B', 'ER', '+BREATH+', 'SIL']\n"
     ]
    }
   ],
   "source": [
    "print([phonemes[ph] for ph in dev[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'D', 'h', 'f', 'I', 'm', 'E', 'l', 'p', 'R', 'h', 'd', 'U', 's', 'i', 'z', 'h', 'l', 'i', 't', 'r', 'h', 'v', 't', 'U', 't', 'i', 'f', 'o', 'R', '?', 'h', 'G', 'i', 'n', 'n', 'O', 'v', 'e', 'm', 'b', 'r', 'A', 'n', 'd', 'd', 'i', 's', 'e', 'm', 'b', 'r', '_', '.']\n"
     ]
    }
   ],
   "source": [
    "print([phonemes_map[ph] for ph in dev[1][0]].jo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
